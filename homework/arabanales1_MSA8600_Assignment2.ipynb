{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVzvvKmZsXti"
      },
      "source": [
        "# MSA8600: Individual Assignment 2\n",
        "\n",
        "**Objective** \n",
        "This assignment aims to familiarize students with Convolutional Neural Networks (CNNs) with the `keras` library, and image processing using the `OpenCV` library. It has `25` points.\n",
        "\n",
        "**Instructions** \n",
        "Please complete the partial code provided and experiment with different CNN architectures and hyperparameters to achieve the desired results.\n",
        "\n",
        "**Submission** \n",
        "After completion, download the notebook from the `File/Download/Download .ipynp` menu, attach it to the assignment on iCollege, and submit it.\n",
        "\n",
        "## Problem Statement\n",
        "\n",
        "1. Use the OpenCV library to preprocess and visualize images.\n",
        "2. Create a CNN model to classify handwritten digits from the popular MNIST dataset. \n",
        "3. Train the model with the training set, and show its accuracy on the test set.\n",
        "4. Modify the architecture and hyper-parameter to achieve better accuracy.\n",
        "5. Report on the results of step 4 by writing a short report."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpA7bDVktskj"
      },
      "source": [
        "### Step 1: data prepreation and visualization (4 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "id": "JcSS9002s9lg",
        "outputId": "43e7b102-6a56-4c12-dab4-b8aec0d2eddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 5s 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/matplotlib/text.py:1279: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  if s != self._text:\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 15 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "\n",
        "mnist = tf.keras.datasets.mnist \n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() # Splits mnist dataset from keras.datasets into training and testing sets\n",
        "\n",
        "# TODO: Normalize the pixel values in the dataset\n",
        "# Hint: Divide the pixel values by 255.0\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "x_train_normalized = datagen.flow(x_train.reshape((-1, 28, 28, 1)))\n",
        "x_test_normalized = datagen.flow(x_test.reshape((-1, 28, 28, 1)))\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "#https://www.geeksforgeeks.org/how-to-normalize-center-and-standardize-image-pixels-in-keras/#\n",
        "\n",
        "# Visualize and preprocess images using OpenCV\n",
        "# Create a window to display the images\n",
        "def visualize_images(images, labels):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "    for i in range(15):\n",
        "        img = images[i]\n",
        "        label = labels[i]\n",
        "\n",
        "        plt.subplot(3, 5, i+1)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.title(label)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "visualize_images(x_train, y_train)\n",
        "\n",
        "#https://www.geeksforgeeks.org/python-grayscaling-of-images-using-opencv/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEF64-Rxt0JK"
      },
      "source": [
        "### Step 2: create a CNN model (6 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WsdCxI-dt2zv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-10 20:00:13.609221: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "def create_cnn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        # TODO: Add a 2D convolutional layer\n",
        "        # Hint: Use a 3x3 kernel and the 'relu' activation function\n",
        "        Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        # TODO: Add a max pooling layer\n",
        "        # Hint: Use a 2x2 pool size\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        # TODO: Add a Flatten layer\n",
        "        Flatten(),\n",
        "        # TODO: Add a dense layer with 128 units and the 'relu' activation function\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        # TODO: Add the output layer with 10 units and the 'softmax' activation function\n",
        "        Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_cnn_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oblavkvbuFMj"
      },
      "source": [
        "### Step 3: train and evaluate the model (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo8Lk8o5uGyR",
        "outputId": "2536d6f6-8c57-40d9-9a18-16936ad73a0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "6750/6750 [==============================] - 74s 11ms/step - loss: 0.1402 - accuracy: 0.9566 - val_loss: 0.0576 - val_accuracy: 0.9842\n",
            "Epoch 2/4\n",
            "6750/6750 [==============================] - 50s 7ms/step - loss: 0.0545 - accuracy: 0.9830 - val_loss: 0.0422 - val_accuracy: 0.9887\n",
            "Epoch 3/4\n",
            "6750/6750 [==============================] - 57s 8ms/step - loss: 0.0360 - accuracy: 0.9891 - val_loss: 0.0427 - val_accuracy: 0.9877\n",
            "Epoch 4/4\n",
            "6750/6750 [==============================] - 44s 7ms/step - loss: 0.0271 - accuracy: 0.9909 - val_loss: 0.0474 - val_accuracy: 0.9883\n",
            "313/313 [==============================] - 2s 4ms/step - loss: 0.0385 - accuracy: 0.9879\n",
            "Test loss: 0.03849831968545914\n",
            "Test accuracy: 0.9879000186920166\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compile the model\n",
        "# Hint: Use the 'adam' optimizer, 'sparse_categorical_crossentropy' loss function, and 'accuracy' metric\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# TODO: Train the model on the training set\n",
        "# Hint: Use 4 or 5 epochs and a batch size of 4, 8, or 16\n",
        "batch_size = 8\n",
        "epochs = 4\n",
        "model.fit(x_train.reshape((-1, 28, 28, 1)), y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "    # {1, 2, 4, 8, 16} - slow \n",
        "    # { [32, 64],[ 128, 256] } - Good starters\n",
        "    # [32, 64] - CPU\n",
        "    # [128, 256] - GPU for more boost\n",
        "\n",
        "# TODO: Evaluate the model on the test set and print the results\n",
        "results = model.evaluate(x_test.reshape((-1, 28, 28, 1)), y_test)\n",
        "print(\"Test loss:\", results[0])\n",
        "print(\"Test accuracy:\", results[1])\n",
        "\n",
        "#https://keras.io/api/metrics/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paUObtdyurLE"
      },
      "source": [
        "### Step 4: experiment with different hyperparameters or CNN architectures (5 points)\n",
        "\n",
        "Try different hyperparameters to improve the performance of the model.\n",
        "\n",
        "> NOTE: Hyperparameters control the learning process of the CNN model. \n",
        "\n",
        "In this assignment, you can explore hyperparameters such as:\n",
        "- **Kernel size in the convolutional layer:** The filter size that is applied to the input data. Common choices are `3x3`, `5x5`, and `7x7`.\n",
        "\n",
        "- **Number of filters in the convolutional layer**: The number of filters applied to the input data in the convolutional layer. This determines the number of feature maps generated in the layer.\n",
        "\n",
        "- **Pool size in the max pooling layer:** The size of the window used for max pooling, typically 2x2 or 3x3.\n",
        "\n",
        "- **Number of units in the dense layer:** The number of neurons in the dense (fully connected) layer. Common choices are 64, 128, 256, and 512.\n",
        "\n",
        "- **Activation functions:** The type of activation functions used in the layers, such as ReLU, Leaky ReLU, or sigmoid.\n",
        "\n",
        "\n",
        "- **Learning rate:** The step size used by the optimizer during weight updates. A smaller learning rate makes the model learn more slowly, while a larger learning rate might cause the model to overshoot the optimal weights.\n",
        "\n",
        "- **Batch size:** The number of training samples used for each weight update during training. Smaller batch sizes can result in more noise during weight updates, while larger batch sizes can provide more stable updates but may require more memory.\n",
        "\n",
        "- **Number of training epochs:** The number of times the model iterates over the entire training dataset. Too few epochs may result in underfitting, while too many epochs can lead to overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxx9nWl_ux1T",
        "outputId": "d36df074-937f-4a6d-aa1a-8ed6953698f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "3375/3375 [==============================] - 94s 28ms/step - loss: 0.1271 - accuracy: 0.9610 - val_loss: 0.0611 - val_accuracy: 0.9807\n",
            "Epoch 2/4\n",
            "3375/3375 [==============================] - 91s 27ms/step - loss: 0.0479 - accuracy: 0.9853 - val_loss: 0.0470 - val_accuracy: 0.9862\n",
            "Epoch 3/4\n",
            "3375/3375 [==============================] - 88s 26ms/step - loss: 0.0312 - accuracy: 0.9901 - val_loss: 0.0403 - val_accuracy: 0.9893\n",
            "Epoch 4/4\n",
            "3375/3375 [==============================] - 88s 26ms/step - loss: 0.0240 - accuracy: 0.9924 - val_loss: 0.0347 - val_accuracy: 0.9905\n",
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0325 - accuracy: 0.9890\n",
            "Test loss: 0.03247974440455437\n",
            "Test accuracy: 0.9890000224113464\n"
          ]
        }
      ],
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "def create_cnn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        # TODO: Add a 2D convolutional layer\n",
        "        # Hint: Use a 5x5 kernel and the 'relu' activation function\n",
        "        Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        # TODO: Add a max pooling layer\n",
        "        # Hint: Use a 2x2 pool size\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        # TODO: Add a Flatten layer\n",
        "        Flatten(),\n",
        "        # TODO: Add a dense layer with 128 units and the 'relu' activation function\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        # TODO: Add the output layer with 10 units and the 'softmax' activation function\n",
        "        Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_cnn_model()\n",
        "\n",
        "# TODO: Compile the model\n",
        "# Hint: Use the 'adam' optimizer, 'sparse_categorical_crossentropy' loss function, and 'accuracy' metric\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# TODO: Train the model on the training set\n",
        "# Hint: Use 4 or 5 epochs and a batch size of 4, 8, or 16\n",
        "batch_size = 16\n",
        "epochs = 4\n",
        "model.fit(x_train.reshape((-1, 28, 28, 1)), y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "    # {1, 2, 4, 8, 16} - slow \n",
        "    # { [32, 64],[ 128, 256] } - Good starters\n",
        "    # [32, 64] - CPU\n",
        "    # [128, 256] - GPU for more boost\n",
        "\n",
        "# TODO: Evaluate the model on the test set and print the results\n",
        "results = model.evaluate(x_test.reshape((-1, 28, 28, 1)), y_test)\n",
        "print(\"Test loss:\", results[0])\n",
        "print(\"Test accuracy:\", results[1])\n",
        "\n",
        "#https://iamaaditya.github.io/2016/03/one-by-one-convolution/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHzhTp3mgzXZ",
        "outputId": "e057c050-03d5-4c19-fcdd-db966846840c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "3375/3375 [==============================] - 249s 73ms/step - loss: 0.1077 - accuracy: 0.9671 - val_loss: 0.0561 - val_accuracy: 0.9843\n",
            "Epoch 2/4\n",
            "3375/3375 [==============================] - 233s 69ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.0407 - val_accuracy: 0.9887\n",
            "Epoch 3/4\n",
            "3375/3375 [==============================] - 307s 91ms/step - loss: 0.0285 - accuracy: 0.9910 - val_loss: 0.0300 - val_accuracy: 0.9915\n",
            "Epoch 4/4\n",
            "3375/3375 [==============================] - 321s 95ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.0360 - val_accuracy: 0.9895\n",
            "313/313 [==============================] - 12s 38ms/step - loss: 0.0274 - accuracy: 0.9911\n",
            "Test loss: 0.02743465267121792\n",
            "Test accuracy: 0.991100013256073\n"
          ]
        }
      ],
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "#Number of filters in the convolutional layer: inc to 512\n",
        "#Pool size in the max pooling layer: 2x2 \n",
        "\n",
        "def create_cnn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        # TODO: Add a 2D convolutional layer\n",
        "        # Hint: Use a 5x5 kernel and the 'relu' activation function\n",
        "        Conv2D(512, (5, 5), padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        # TODO: Add a max pooling layer\n",
        "        # Hint: Use a 2x2 pool size\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        # TODO: Add a Flatten layer\n",
        "        Flatten(),\n",
        "        # TODO: Add a dense layer with 128 units and the 'relu' activation function\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        # TODO: Add the output layer with 10 units and the 'softmax' activation function\n",
        "        Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_cnn_model()\n",
        "\n",
        "# TODO: Compile the model\n",
        "# Hint: Use the 'adam' optimizer, 'sparse_categorical_crossentropy' loss function, and 'accuracy' metric\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# TODO: Train the model on the training set\n",
        "# Hint: Use 4 or 5 epochs and a batch size of 4, 8, or 16\n",
        "batch_size = 16\n",
        "epochs = 4\n",
        "model.fit(x_train.reshape((-1, 28, 28, 1)), y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "    # {1, 2, 4, 8, 16} - slow \n",
        "    # { [32, 64],[ 128, 256] } - Good starters\n",
        "    # [32, 64] - CPU\n",
        "    # [128, 256] - GPU for more boost\n",
        "\n",
        "# TODO: Evaluate the model on the test set and print the results\n",
        "results = model.evaluate(x_test.reshape((-1, 28, 28, 1)), y_test)\n",
        "print(\"Test loss:\", results[0])\n",
        "print(\"Test accuracy:\", results[1])\n",
        "\n",
        "#512 inc time to wait / same accuracy from previous\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "#Number of filters in the convolutional layer: inc to 512\n",
        "#Pool size in the max pooling layer: 2x2 \n",
        "\n",
        "This is one took the most out of all the CNN models due to increase of the CV layer to 512 but had a less loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_GFqAFc6hw0Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "3375/3375 [==============================] - 193s 57ms/step - loss: 0.1110 - accuracy: 0.9661 - val_loss: 0.0471 - val_accuracy: 0.9862\n",
            "Epoch 2/4\n",
            "3375/3375 [==============================] - 185s 55ms/step - loss: 0.0435 - accuracy: 0.9861 - val_loss: 0.0382 - val_accuracy: 0.9895\n",
            "Epoch 3/4\n",
            "3375/3375 [==============================] - 179s 53ms/step - loss: 0.0296 - accuracy: 0.9904 - val_loss: 0.0494 - val_accuracy: 0.9865\n",
            "Epoch 4/4\n",
            "3375/3375 [==============================] - 186s 55ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.0538 - val_accuracy: 0.9867\n",
            "313/313 [==============================] - 9s 29ms/step - loss: 0.0450 - accuracy: 0.9862\n",
            "Test loss: 0.04504884406924248\n",
            "Test accuracy: 0.9861999750137329\n"
          ]
        }
      ],
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "#Number of filters in the convolutional layer: inc to 512\n",
        "#Pool size in the max pooling layer: 2x2 \n",
        "#Number of units in the dense layer: dec 64\n",
        "\n",
        "\n",
        "def create_cnn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        # TODO: Add a 2D convolutional layer\n",
        "        # Hint: Use a 5x5 kernel and the 'relu' activation function\n",
        "        Conv2D(512, (5, 5), padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        # TODO: Add a max pooling layer\n",
        "        # Hint: Use a 2x2 pool size\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        # TODO: Add a Flatten layer\n",
        "        Flatten(),\n",
        "        # TODO: Add a dense layer with 128 units and the 'relu' activation function\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        # TODO: Add the output layer with 10 units and the 'softmax' activation function\n",
        "        Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_cnn_model()\n",
        "\n",
        "# TODO: Compile the model\n",
        "# Hint: Use the 'adam' optimizer, 'sparse_categorical_crossentropy' loss function, and 'accuracy' metric\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# TODO: Train the model on the training set\n",
        "# Hint: Use 4 or 5 epochs and a batch size of 4, 8, or 16\n",
        "batch_size = 16\n",
        "epochs = 4\n",
        "model.fit(x_train.reshape((-1, 28, 28, 1)), y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "    # {1, 2, 4, 8, 16} - slow \n",
        "    # { [32, 64],[ 128, 256] } - Good starters\n",
        "    # [32, 64] - CPU\n",
        "    # [128, 256] - GPU for more boost\n",
        "\n",
        "# TODO: Evaluate the model on the test set and print the results\n",
        "results = model.evaluate(x_test.reshape((-1, 28, 28, 1)), y_test)\n",
        "print(\"Test loss:\", results[0])\n",
        "print(\"Test accuracy:\", results[1])\n",
        "\n",
        "#results seemed to be lowered"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "#Number of filters in the convolutional layer: inc to 512\n",
        "#Pool size in the max pooling layer: 2x2 \n",
        "#Number of units in the dense layer: dec 64\n",
        "\n",
        "results seemed to be lowered with a more loss of 0.045"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bfFO-XK1jDnZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "3375/3375 [==============================] - 243s 71ms/step - loss: 2.3099 - accuracy: 0.1069 - val_loss: 2.3036 - val_accuracy: 0.1113\n",
            "Epoch 2/4\n",
            "3375/3375 [==============================] - 259s 77ms/step - loss: 2.3049 - accuracy: 0.1060 - val_loss: 2.3081 - val_accuracy: 0.1050\n",
            "Epoch 3/4\n",
            "3375/3375 [==============================] - 235s 70ms/step - loss: 2.3051 - accuracy: 0.1068 - val_loss: 2.3090 - val_accuracy: 0.1050\n",
            "Epoch 4/4\n",
            "3375/3375 [==============================] - 293s 87ms/step - loss: 2.3052 - accuracy: 0.1035 - val_loss: 2.3056 - val_accuracy: 0.1050\n",
            "313/313 [==============================] - 10s 31ms/step - loss: 2.3036 - accuracy: 0.1135\n",
            "Test loss: 2.303586959838867\n",
            "Test accuracy: 0.11349999904632568\n"
          ]
        }
      ],
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "#Number of filters in the convolutional layer: inc to 512\n",
        "#Pool size in the max pooling layer: 2x2 \n",
        "#Number of units in the dense layer: dec 64\n",
        "#Activation functions: sigmoid\n",
        "\n",
        "\n",
        "\n",
        "def create_cnn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        Conv2D(512, (5, 5), padding=\"same\", activation=\"sigmoid\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(64, activation=\"sigmoid\"),\n",
        "        Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_cnn_model()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 4\n",
        "model.fit(x_train.reshape((-1, 28, 28, 1)), y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "    # {1, 2, 4, 8, 16} - slow \n",
        "    # { [32, 64],[ 128, 256] } - Good starters\n",
        "    # [32, 64] - CPU\n",
        "    # [128, 256] - GPU for more boost\n",
        "\n",
        "results = model.evaluate(x_test.reshape((-1, 28, 28, 1)), y_test)\n",
        "print(\"Test loss:\", results[0])\n",
        "print(\"Test accuracy:\", results[1])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "#Number of filters in the convolutional layer: inc to 512\n",
        "#Pool size in the max pooling layer: 2x2 \n",
        "#Number of units in the dense layer: dec 64\n",
        "#Activation functions: sigmoid\n",
        "\n",
        "The results were severly lowered with a test loss of 2.3 and an accuracy of 0.11 which is significantly lower than using relu activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Gsynl-D0j6dX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "3375/3375 [==============================] - 45s 13ms/step - loss: 0.1456 - accuracy: 0.9555 - val_loss: 0.0562 - val_accuracy: 0.9847\n",
            "Epoch 2/4\n",
            "3375/3375 [==============================] - 39s 11ms/step - loss: 0.0534 - accuracy: 0.9834 - val_loss: 0.0495 - val_accuracy: 0.9852\n",
            "Epoch 3/4\n",
            "3375/3375 [==============================] - 39s 12ms/step - loss: 0.0374 - accuracy: 0.9882 - val_loss: 0.0413 - val_accuracy: 0.9872\n",
            "Epoch 4/4\n",
            "3375/3375 [==============================] - 41s 12ms/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.0461 - val_accuracy: 0.9880\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0462 - accuracy: 0.9851\n",
            "Test loss: 0.046164512634277344\n",
            "Test accuracy: 0.9850999712944031\n"
          ]
        }
      ],
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "#Number of filters in the convolutional layer: change back to 64\n",
        "#Pool size in the max pooling layer: 2x2 \n",
        "#Number of units in the dense layer: dec 64\n",
        "#Activation functions: relu, change back to the original\n",
        "#Learning rate: same\n",
        "\n",
        "def create_cnn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_cnn_model()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "epochs = 4\n",
        "model.fit(x_train.reshape((-1, 28, 28, 1)), y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "    # {1, 2, 4, 8, 16} - slow \n",
        "    # { [32, 64],[ 128, 256] } - Good starters\n",
        "    # [32, 64] - CPU\n",
        "    # [128, 256] - GPU for more boost\n",
        "\n",
        "results = model.evaluate(x_test.reshape((-1, 28, 28, 1)), y_test)\n",
        "print(\"Test loss:\", results[0])\n",
        "print(\"Test accuracy:\", results[1])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "#Number of filters in the convolutional layer: change back to 64\n",
        "#Pool size in the max pooling layer: 2x2 \n",
        "#Number of units in the dense layer: dec 64\n",
        "#Activation functions: relu, change back to the original\n",
        "#Learning rate: same\n",
        "\n",
        "I changed the activation function back to relu since sigmoid takes longers to process, i left the learning rate the same because I believe it runs as a steady process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CepuZZ3ekLfD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "6750/6750 [==============================] - 53s 8ms/step - loss: 0.1271 - accuracy: 0.9610 - val_loss: 0.0575 - val_accuracy: 0.9832\n",
            "Epoch 2/4\n",
            "6750/6750 [==============================] - 51s 8ms/step - loss: 0.0493 - accuracy: 0.9849 - val_loss: 0.0404 - val_accuracy: 0.9880\n",
            "Epoch 3/4\n",
            "6750/6750 [==============================] - 51s 7ms/step - loss: 0.0354 - accuracy: 0.9886 - val_loss: 0.0376 - val_accuracy: 0.9905\n",
            "Epoch 4/4\n",
            "6750/6750 [==============================] - 51s 7ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.0337 - val_accuracy: 0.9918\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0335 - accuracy: 0.9892\n",
            "Test loss: 0.033542387187480927\n",
            "Test accuracy: 0.9891999959945679\n"
          ]
        }
      ],
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "#Number of filters in the convolutional layer: 64\n",
        "#Pool size in the max pooling layer: 2x2 \n",
        "#Number of units in the dense layer: dec 64\n",
        "#Activation functions: relu\n",
        "#Learning rate: same\n",
        "#Batch size: 8 \n",
        "\n",
        "\n",
        "\n",
        "def create_cnn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_cnn_model()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        "epochs = 4\n",
        "model.fit(x_train.reshape((-1, 28, 28, 1)), y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "    # {1, 2, 4, 8, 16} - slow \n",
        "    # { [32, 64],[ 128, 256] } - Good starters\n",
        "    # [32, 64] - CPU\n",
        "    # [128, 256] - GPU for more boost\n",
        "\n",
        "results = model.evaluate(x_test.reshape((-1, 28, 28, 1)), y_test)\n",
        "print(\"Test loss:\", results[0])\n",
        "print(\"Test accuracy:\", results[1])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "#Number of filters in the convolutional layer: 64\n",
        "#Pool size in the max pooling layer: 2x2 \n",
        "#Number of units in the dense layer: dec 64\n",
        "#Activation functions: relu\n",
        "#Learning rate: same\n",
        "#Batch size: 8 \n",
        "\n",
        "Changing the batch size decrease time from the orginal which means batch size will be increased for lower time and accruacy and loss is similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Q-WUNvlckvoS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "6750/6750 [==============================] - 53s 8ms/step - loss: 0.1356 - accuracy: 0.9578 - val_loss: 0.0647 - val_accuracy: 0.9803\n",
            "Epoch 2/5\n",
            "6750/6750 [==============================] - 51s 8ms/step - loss: 0.0503 - accuracy: 0.9839 - val_loss: 0.0559 - val_accuracy: 0.9838\n",
            "Epoch 3/5\n",
            "6750/6750 [==============================] - 48s 7ms/step - loss: 0.0346 - accuracy: 0.9894 - val_loss: 0.0447 - val_accuracy: 0.9867\n",
            "Epoch 4/5\n",
            "6750/6750 [==============================] - 193s 29ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0427 - val_accuracy: 0.9868\n",
            "Epoch 5/5\n",
            "6750/6750 [==============================] - 50s 7ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.0479 - val_accuracy: 0.9887\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0448 - accuracy: 0.9879\n",
            "Test loss: 0.04475928843021393\n",
            "Test accuracy: 0.9879000186920166\n"
          ]
        }
      ],
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "#Number of filters in the convolutional layer: 64\n",
        "#Pool size in the max pooling layer: 2x2 \n",
        "#Number of units in the dense layer: dec 64\n",
        "#Activation functions: relu\n",
        "#Learning rate: same\n",
        "#Batch size: 8 \n",
        "#Number of training epochs: 5\n",
        "\n",
        "def create_cnn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        Conv2D(64, (5, 5), padding=\"same\", activation=\"relu\"),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(64, activation=\"relu\"),\n",
        "        Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_cnn_model()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "batch_size = 8\n",
        "epochs = 5\n",
        "model.fit(x_train.reshape((-1, 28, 28, 1)), y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "    # {1, 2, 4, 8, 16} - slow \n",
        "    # { [32, 64],[ 128, 256] } - Good starters\n",
        "    # [32, 64] - CPU\n",
        "    # [128, 256] - GPU for more boost\n",
        "\n",
        "results = model.evaluate(x_test.reshape((-1, 28, 28, 1)), y_test)\n",
        "print(\"Test loss:\", results[0])\n",
        "print(\"Test accuracy:\", results[1])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Kernel size in the convolutional layer: 5x5\n",
        "#Number of filters in the convolutional layer: 64\n",
        "#Pool size in the max pooling layer: 2x2 \n",
        "#Number of units in the dense layer: dec 64\n",
        "#Activation functions: relu\n",
        "#Learning rate: same\n",
        "#Batch size: 8 \n",
        "#Number of training epochs: 5\n",
        "\n",
        "Increase the epoch increase the time for processing training with a slightly larger loss and lower accuracy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2OUPeAcvXIZ"
      },
      "source": [
        "### Step 5: report (5 points)\n",
        "\n",
        "Discuss the hyperparameters explored, along with the resulting performance metrics. What values of hyperparameters make the model underperform and what values make it more accurate? Did you encounter errors?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tMknLUz_vxoJ"
      },
      "source": [
        "wrote it under each cell *Write your reporting by editing this text cell*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
