{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MSA8600: Individual Assignment 2\n",
        "\n",
        "**Objective** \n",
        "This assignment aims to familiarize students with Convolutional Neural Networks (CNNs) with the `keras` library, and image processing using the `OpenCV` library. It has `25` points.\n",
        "\n",
        "**Instructions** \n",
        "Please complete the partial code provided and experiment with different CNN architectures and hyperparameters to achieve the desired results.\n",
        "\n",
        "**Submission** \n",
        "After completion, download the notebook from the `File/Download/Download .ipynp` menu, attach it to the assignment on iCollege, and submit it.\n",
        "\n",
        "## Problem Statement\n",
        "\n",
        "1. Use the OpenCV library to preprocess and visualize images.\n",
        "2. Create a CNN model to classify handwritten digits from the popular MNIST dataset. \n",
        "3. Train the model with the training set, and show its accuracy on the test set.\n",
        "4. Modify the architecture and hyper-parameter to achieve better accuracy.\n",
        "5. Report on the results of step 4 by writing a short report."
      ],
      "metadata": {
        "id": "rVzvvKmZsXti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: data prepreation and visualization (4 points)"
      ],
      "metadata": {
        "id": "LpA7bDVktskj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist = tf.keras.datasets.mnist \n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() # Splits mnist dataset from keras.datasets into training and testing sets\n",
        "\n",
        "# TODO: Normalize the pixel values in the dataset\n",
        "# Hint: Divide the pixel values by 255.0\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Visualize and preprocess images using OpenCV\n",
        "def visualize_images(images, labels):\n",
        "    # TODO: Use OpenCV to visualize the first 15 images in the dataset\n",
        "    pass\n",
        "\n",
        "visualize_images(x_train, y_train)\n"
      ],
      "metadata": {
        "id": "JcSS9002s9lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: create a CNN model (6 points)"
      ],
      "metadata": {
        "id": "fEF64-Rxt0JK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        # TODO: Add a 2D convolutional layer\n",
        "        # Hint: Use a 3x3 kernel and the 'relu' activation function\n",
        "\n",
        "        # TODO: Add a max pooling layer\n",
        "        # Hint: Use a 2x2 pool size\n",
        "\n",
        "        # TODO: Add a Flatten layer\n",
        "\n",
        "        # TODO: Add a dense layer with 128 units and the 'relu' activation function\n",
        "\n",
        "        # TODO: Add the output layer with 10 units and the 'softmax' activation function\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_cnn_model()"
      ],
      "metadata": {
        "id": "WsdCxI-dt2zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: train and evaluate the model (5 points)"
      ],
      "metadata": {
        "id": "oblavkvbuFMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_model(model):\n",
        "    # TODO: Compile the model\n",
        "    # Hint: Use the 'adam' optimizer, 'sparse_categorical_crossentropy' loss function, and 'accuracy' metric\n",
        "\n",
        "    # TODO: Train the model on the training set\n",
        "    # Hint: Use 4 or 5 epochs and a batch size of 4, 8, or 16\n",
        "\n",
        "    # TODO: Evaluate the model on the test set and print the results\n",
        "    pass\n",
        "\n",
        "train_and_evaluate_model(model)\n"
      ],
      "metadata": {
        "id": "Qo8Lk8o5uGyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: experiment with different hyperparameters or CNN architectures (5 points)\n",
        "\n",
        "Try different hyperparameters to improve the performance of the model.\n",
        "\n",
        "> NOTE: Hyperparameters control the learning process of the CNN model. \n",
        "\n",
        "In this assignment, you can explore hyperparameters such as:\n",
        "- **Kernel size in the convolutional layer:** The filter size that is applied to the input data. Common choices are `3x3`, `5x5`, and `7x7`.\n",
        "\n",
        "- **Number of filters in the convolutional layer**: The number of filters applied to the input data in the convolutional layer. This determines the number of feature maps generated in the layer.\n",
        "\n",
        "- **Pool size in the max pooling layer:** The size of the window used for max pooling, typically 2x2 or 3x3.\n",
        "\n",
        "- **Number of units in the dense layer:** The number of neurons in the dense (fully connected) layer. Common choices are 64, 128, 256, and 512.\n",
        "\n",
        "- **Activation functions:** The type of activation functions used in the layers, such as ReLU, Leaky ReLU, or sigmoid.\n",
        "\n",
        "\n",
        "- **Learning rate:** The step size used by the optimizer during weight updates. A smaller learning rate makes the model learn more slowly, while a larger learning rate might cause the model to overshoot the optimal weights.\n",
        "\n",
        "- **Batch size:** The number of training samples used for each weight update during training. Smaller batch sizes can result in more noise during weight updates, while larger batch sizes can provide more stable updates but may require more memory.\n",
        "\n",
        "- **Number of training epochs:** The number of times the model iterates over the entire training dataset. Too few epochs may result in underfitting, while too many epochs can lead to overfitting."
      ],
      "metadata": {
        "id": "paUObtdyurLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: write your code here"
      ],
      "metadata": {
        "id": "Uxx9nWl_ux1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: report (5 points)\n",
        "\n",
        "Discuss the hyperparameters explored, along with the resulting performance metrics. What values of hyperparameters make the model underperform and what values make it more accurate? Did you encounter errors?"
      ],
      "metadata": {
        "id": "a2OUPeAcvXIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Write your reporting by editing this text cell*"
      ],
      "metadata": {
        "id": "tMknLUz_vxoJ"
      }
    }
  ]
}